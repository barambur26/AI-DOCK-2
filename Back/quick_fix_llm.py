#!/usr/bin/env python3
"""
üöë Quick Fix - LLM Provider Issues
This script helps fix OpenAI quota issues for immediate testing
"""

import asyncio
import os
from sqlalchemy.ext.asyncio import AsyncSession
from app.core.database import get_async_db
from app.models.llm_config import LLMConfiguration, LLMProvider
from sqlalchemy import select

async def update_openai_key():
    """Update OpenAI API key in database"""
    print("üîë Updating OpenAI configuration...")
    
    # Get new API key
    new_key = input("üîë Enter your new OpenAI API key (or press Enter to skip): ").strip()
    
    if not new_key:
        print("‚è≠Ô∏è Skipping OpenAI key update")
        return False
    
    if not new_key.startswith("sk-"):
        print("‚ùå Invalid API key format. Should start with 'sk-'")
        return False
    
    async for db in get_async_db():
        try:
            # Find OpenAI configuration
            result = await db.execute(
                select(LLMConfiguration).where(LLMConfiguration.name == "OpenAI ChatGPT")
            )
            config = result.scalar_one_or_none()
            
            if config:
                config.api_key = new_key
                await db.commit()
                print("‚úÖ OpenAI key updated!")
                return True
            else:
                print("‚ùå OpenAI configuration not found")
                return False
                
        except Exception as e:
            print(f"‚ùå Database error: {e}")
            return False
        finally:
            await db.close()
            break

async def create_mock_provider():
    """Create a mock LLM provider for testing"""
    print("üé≠ Creating mock LLM provider...")
    
    async for db in get_async_db():
        try:
            # Check if mock provider exists
            result = await db.execute(
                select(LLMConfiguration).where(LLMConfiguration.name == "Mock LLM (Testing)")
            )
            existing = result.scalar_one_or_none()
            
            if existing:
                print("‚ÑπÔ∏è Mock provider already exists, updating...")
                config = existing
            else:
                print("‚ûï Creating new mock provider...")
                config = LLMConfiguration()
            
            # Configure mock provider
            config.name = "Mock LLM (Testing)"
            config.provider = LLMProvider.OPENAI  # Use OpenAI format
            config.provider_name = "Mock"
            config.api_key = "mock-api-key-for-testing"
            config.base_url = "https://httpbin.org/post"  # Mock endpoint
            config.default_model = "mock-gpt-3.5"
            config.available_models = ["mock-gpt-3.5", "mock-gpt-4"]
            config.is_active = True
            config.is_public = True
            config.priority = 0  # Highest priority
            config.max_tokens_per_request = 1000
            config.rate_limit_per_minute = 1000
            config.cost_per_1k_input_tokens = 0.0
            config.cost_per_1k_output_tokens = 0.0
            config.has_cost_tracking = False
            
            config.configuration_params = {
                "temperature": 0.7,
                "max_tokens": 100
            }
            
            if not existing:
                db.add(config)
            
            await db.commit()
            
            print("‚úÖ Mock provider created!")
            print("üìù This provider will return test responses")
            print("üéØ Perfect for testing UI without API costs")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error creating mock provider: {e}")
            return False
        finally:
            await db.close()
            break

async def disable_problematic_providers():
    """Disable providers that are causing quota issues"""
    print("üîß Disabling problematic providers...")
    
    async for db in get_async_db():
        try:
            # Find all OpenAI configurations
            result = await db.execute(
                select(LLMConfiguration).where(LLMConfiguration.provider == LLMProvider.OPENAI)
            )
            configs = result.scalars().all()
            
            for config in configs:
                if "ChatGPT" in config.name:
                    config.is_active = False
                    print(f"‚è∏Ô∏è Disabled: {config.name}")
            
            await db.commit()
            print("‚úÖ Problematic providers disabled")
            
        except Exception as e:
            print(f"‚ùå Error disabling providers: {e}")
        finally:
            await db.close()
            break

async def show_current_status():
    """Show current LLM provider status"""
    print("\nüìä Current LLM Provider Status:")
    print("-" * 40)
    
    async for db in get_async_db():
        try:
            result = await db.execute(select(LLMConfiguration))
            configs = result.scalars().all()
            
            if not configs:
                print("‚ùå No LLM providers configured")
                return
            
            for config in configs:
                status = "üü¢ Active" if config.is_active else "üî¥ Inactive"
                priority = config.priority or 0
                print(f"{status} | {config.name}")
                print(f"    Provider: {config.provider_name}")
                print(f"    Model: {config.default_model}")
                print(f"    Priority: {priority}")
                print(f"    Cost tracking: {'Yes' if config.has_cost_tracking else 'No'}")
                print()
                
        except Exception as e:
            print(f"‚ùå Error checking status: {e}")
        finally:
            await db.close()
            break

def show_menu():
    """Show options menu"""
    print("\nüõ†Ô∏è Quick Fix Options:")
    print("1. Update OpenAI API key")
    print("2. Create mock provider for testing")
    print("3. Disable problematic providers")
    print("4. Show current provider status")
    print("5. Exit")
    return input("\nüéØ Choose option (1-5): ").strip()

async def main():
    """Main menu"""
    print("üöë AI Dock - Quick LLM Fix")
    print("=" * 40)
    print()
    print("üéØ Purpose: Fix OpenAI quota issues for immediate testing")
    print()
    
    while True:
        choice = show_menu()
        
        if choice == "1":
            await update_openai_key()
        elif choice == "2":
            await create_mock_provider()
        elif choice == "3":
            await disable_problematic_providers()
        elif choice == "4":
            await show_current_status()
        elif choice == "5":
            print("üëã Goodbye!")
            break
        else:
            print("‚ùå Invalid choice. Please enter 1-5.")
        
        input("\n‚è∏Ô∏è Press Enter to continue...")
    
    print("\nüìã Next Steps:")
    print("1. Restart your backend server")
    print("2. Go to http://localhost:8080/chat")
    print("3. Test with working provider")
    print("4. Add billing to OpenAI account for production")

if __name__ == "__main__":
    asyncio.run(main())
